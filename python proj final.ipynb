{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e372bbd-3c58-4c74-8be3-bcec7d868fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the starting URL:   https://github.com/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting crawl...\n",
      "Crawling:  https://github.com/ at depth 0 (Visited: 0)\n",
      "[Using A* Algorithm] Crawling: https://github.com/organizations/enterprise_plan?ref_cta=Start+a+free+enterprise+trial&ref_loc=Home+campaign+footer&ref_page=%2F\n",
      "[A*] Processing URL with priority 128: https://github.com/organizations/enterprise_plan?ref_cta=Start+a+free+enterprise+trial&ref_loc=Home+campaign+footer&ref_page=%2F\n",
      "[Using DFS Algorithm] Crawling: https://github.com/features/copilot#enterprise\n",
      "[Using DFS Algorithm] Crawling: https://github.com/#productivity\n",
      "[Using A* Algorithm] Crawling: https://docs.github.com/get-started/exploring-integrations/about-building-integrations\n",
      "[A*] Processing URL with priority 86: https://docs.github.com/get-started/exploring-integrations/about-building-integrations\n",
      "[Using A* Algorithm] Crawling: https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax\n",
      "[A*] Processing URL with priority 96: https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax\n",
      "[Using DFS Algorithm] Crawling: https://github.com/security\n",
      "[Using BFS Algorithm] Crawling: https://skills.github.com\n",
      "[Using BFS Algorithm] Crawling: https://github.blog\n",
      "[Using DFS Algorithm] Crawling: https://github.com/curl\n",
      "[Using DFS Algorithm] Crawling: https://github.com/github/site-policy/pull/582\n",
      "[Using DFS Algorithm] Crawling: https://github.com/enterprise\n",
      "[Using DFS Algorithm] Crawling: https://github.com/solutions/devops\n",
      "[Using DFS Algorithm] Crawling: https://github.com/edu\n",
      "[Using DFS Algorithm] Crawling: https://github.com/enterprise/advanced-security\n",
      "[Using DFS Algorithm] Crawling: https://github.com/about/diversity\n",
      "[Using A* Algorithm] Crawling: https://github.com/solutions/industries/manufacturing\n",
      "[A*] Processing URL with priority 53: https://github.com/solutions/industries/manufacturing\n",
      "[Using DFS Algorithm] Crawling: https://www.tiktok.com/@github\n",
      "[Using DFS Algorithm] Crawling: https://github.com/yyx990803\n",
      "[Using BFS Algorithm] Crawling: https://github.careers\n",
      "[Using DFS Algorithm] Crawling: https://github.com/git-guides\n",
      "[Using DFS Algorithm] Crawling: https://github.com/#start-of-content\n",
      "[Using BFS Algorithm] Crawling: https://desktop.github.com\n",
      "[Using DFS Algorithm] Crawling: https://github.com/dayhaysoos\n",
      "[Using DFS Algorithm] Crawling: https://github.com/features/codespaces\n",
      "[Using DFS Algorithm] Crawling: https://github.com/enterprise/startups\n",
      "[Using DFS Algorithm] Crawling: https://github.com/features/copilot\n",
      "[Using DFS Algorithm] Crawling: https://github.com/topics\n",
      "[Using DFS Algorithm] Crawling: https://resources.github.com/devops/tools/compare\n",
      "[Using DFS Algorithm] Crawling: https://www.youtube.com/github\n",
      "[Using DFS Algorithm] Crawling: https://github.com/resources/articles\n",
      "[Using A* Algorithm] Crawling: https://github.blog/2023-01-25-100-million-developers-and-counting/\n",
      "[A*] Processing URL with priority 67: https://github.blog/2023-01-25-100-million-developers-and-counting/\n",
      "[Using BFS Algorithm] Crawling: https://services.github.com\n",
      "[Using DFS Algorithm] Crawling: https://github.com/collections\n",
      "[Using A* Algorithm] Crawling: https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F&source=header-home\n",
      "[A*] Processing URL with priority 99: https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F&source=header-home\n",
      "[Using DFS Algorithm] Crawling: https://www.twitch.tv/github\n",
      "[Using BFS Algorithm] Crawling: https://shop.github.com\n",
      "[Using DFS Algorithm] Crawling: https://github.com/solutions/ci-cd\n",
      "[Using DFS Algorithm] Crawling: https://github.com/features\n",
      "[Using DFS Algorithm] Crawling: https://github.com/features/issues\n",
      "[Using DFS Algorithm] Crawling: https://resources.github.com/learn/pathways\n",
      "[Using DFS Algorithm] Crawling: https://github.com/prophen\n",
      "[Using DFS Algorithm] Crawling: https://github.com/#security\n",
      "[Using DFS Algorithm] Crawling: https://www.linkedin.com/company/github\n",
      "[Using BFS Algorithm] Crawling: https://www.githubstatus.com\n",
      "[Using DFS Algorithm] Crawling: https://resources.github.com/security/sast/\n",
      "[Using DFS Algorithm] Crawling: https://github.com/solutions/industries/healthcare\n",
      "[Using DFS Algorithm] Crawling: https://github.com/eslint\n",
      "[Using DFS Algorithm] Crawling: https://github.com/resources/articles/security\n",
      "[Using A* Algorithm] Crawling: https://github.com/resources/articles/software-development\n",
      "[A*] Processing URL with priority 58: https://github.com/resources/articles/software-development\n",
      "[Using DFS Algorithm] Crawling: https://github.com/premium-support\n",
      "[Using BFS Algorithm] Crawling: https://cli.github.com\n",
      "[Using DFS Algorithm] Crawling: https://github.com/sitemap\n",
      "[Using DFS Algorithm] Crawling: https://github.com/features/actions\n",
      "[Using DFS Algorithm] Crawling: https://github.com/newsroom\n",
      "[Using DFS Algorithm] Crawling: https://github.com/#collaboration\n",
      "[Using A* Algorithm] Crawling: https://github.com/organizations/enterprise_plan?ref_cta=Start+a+free+enterprise+trial&ref_loc=homepage+sticky+nav&ref_page=%2F\n",
      "[A*] Processing URL with priority 127: https://github.com/organizations/enterprise_plan?ref_cta=Start+a+free+enterprise+trial&ref_loc=homepage+sticky+nav&ref_page=%2F\n",
      "[Using DFS Algorithm] Crawling: https://github.com/about\n",
      "[Using DFS Algorithm] Crawling: https://www.facebook.com/GitHub\n",
      "[Using DFS Algorithm] Crawling: https://github.com/features/code-review\n",
      "[Using DFS Algorithm] Crawling: https://resources.github.com/forrester/\n",
      "[Using DFS Algorithm] Crawling: https://github.com/team\n",
      "[Using A* Algorithm] Crawling: https://github.com/customer-stories?type=enterprise\n",
      "[A*] Processing URL with priority 51: https://github.com/customer-stories?type=enterprise\n",
      "[Using DFS Algorithm] Crawling:  https://github.com/\n",
      "[Using BFS Algorithm] Crawling: https://support.github.com?tags=dotcom-footer\n",
      "[Using DFS Algorithm] Crawling: https://github.com/readme\n",
      "[Using DFS Algorithm] Crawling: https://github.com/features/security/code\n",
      "[Using DFS Algorithm] Crawling: https://github.com/login\n",
      "[Using DFS Algorithm] Crawling: https://github.com/github\n",
      "[Using A* Algorithm] Crawling: https://github.com/features/security/software-supply-chain\n",
      "[A*] Processing URL with priority 58: https://github.com/features/security/software-supply-chain\n",
      "[Using BFS Algorithm] Crawling: https://socialimpact.github.com\n",
      "[Using BFS Algorithm] Crawling: https://github.community\n",
      "[Using DFS Algorithm] Crawling: https://github.com/\n",
      "[Using A* Algorithm] Crawling: https://githubuniverse.com/?utm_source=github&utm_medium=banner&utm_campaign=24bannerheader10li\n",
      "[A*] Processing URL with priority 95: https://githubuniverse.com/?utm_source=github&utm_medium=banner&utm_campaign=24bannerheader10li\n",
      "[Using DFS Algorithm] Crawling: https://github.com/customer-stories\n",
      "[Using DFS Algorithm] Crawling: https://github.com/features/discussions\n",
      "[Using DFS Algorithm] Crawling: https://github.com/imolorhe\n",
      "[Using BFS Algorithm] Crawling: https://partner.github.com\n",
      "[Using DFS Algorithm] Crawling: https://github.com/mobile\n",
      "[Using DFS Algorithm] Crawling: https://github.com/solutions/devsecops\n",
      "[Using DFS Algorithm] Crawling: https://github.com/resources/articles/ai\n",
      "[Using DFS Algorithm] Crawling: https://github.com/kazupon\n",
      "[Using DFS Algorithm] Crawling: https://github.com/github/roadmap\n",
      "[Using DFS Algorithm] Crawling: https://x.com/github\n",
      "[Using DFS Algorithm] Crawling: https://github.com/sindresorhus\n",
      "[Using DFS Algorithm] Crawling: https://resources.github.com/newsletter/\n",
      "[Using DFS Algorithm] Crawling: https://github.com/features/security\n",
      "[Using A* Algorithm] Crawling: https://docs.github.com/site-policy/github-terms/github-terms-of-service\n",
      "[A*] Processing URL with priority 72: https://docs.github.com/site-policy/github-terms/github-terms-of-service\n",
      "[Using BFS Algorithm] Crawling: https://docs.github.com\n",
      "[Using DFS Algorithm] Crawling: https://github.com/sponsors\n",
      "[Using DFS Algorithm] Crawling: https://github.com/pricing\n",
      "[Using A* Algorithm] Crawling: https://github.com/join?ref_cta=Sign+up+for+GitHub&ref_loc=homepage+sticky+nav&ref_page=%2F&source=homepage-sticky-nav\n",
      "[A*] Processing URL with priority 118: https://github.com/join?ref_cta=Sign+up+for+GitHub&ref_loc=homepage+sticky+nav&ref_page=%2F&source=homepage-sticky-nav\n",
      "[Using DFS Algorithm] Crawling: https://github.com/commandpost\n",
      "[Using A* Algorithm] Crawling: https://github.com/organizations/enterprise_plan?ref_cta=Start+a+free+enterprise+trial&ref_loc=Home+campaign+hero&ref_page=%2F\n",
      "[A*] Processing URL with priority 126: https://github.com/organizations/enterprise_plan?ref_cta=Start+a+free+enterprise+trial&ref_loc=Home+campaign+hero&ref_page=%2F\n",
      "[Using A* Algorithm] Crawling: https://github.com/solutions/industries/financial-services\n",
      "[A*] Processing URL with priority 58: https://github.com/solutions/industries/financial-services\n",
      "[Using BFS Algorithm] Crawling: https://resources.github.com\n",
      "[Using DFS Algorithm] Crawling: https://github.com/resources/articles/devops\n",
      "[Using A* Algorithm] Crawling: https://docs.github.com/site-policy/privacy-policies/github-privacy-statement\n",
      "[A*] Processing URL with priority 77: https://docs.github.com/site-policy/privacy-policies/github-privacy-statement\n",
      "[Using DFS Algorithm] Crawling: https://github.com/enterprise/premium-support\n",
      "[Using DFS Algorithm] Crawling: https://github.com/trending\n",
      "\n",
      "Indexed Links:\n",
      "1: https://github.com/organizations/enterprise_plan?ref_cta=Start+a+free+enterprise+trial&ref_loc=Home+campaign+footer&ref_page=%2F\n",
      "2: https://github.com/features/copilot#enterprise\n",
      "3: https://github.com/#productivity\n",
      "4: https://docs.github.com/get-started/exploring-integrations/about-building-integrations\n",
      "5: https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax\n",
      "6: https://github.com/security\n",
      "7: https://skills.github.com\n",
      "8: https://github.blog\n",
      "9: https://github.com/curl\n",
      "10: https://github.com/github/site-policy/pull/582\n",
      "11: https://github.com/enterprise\n",
      "12: https://github.com/solutions/devops\n",
      "13: https://github.com/edu\n",
      "14: https://github.com/enterprise/advanced-security\n",
      "15: https://github.com/about/diversity\n",
      "16: https://github.com/solutions/industries/manufacturing\n",
      "17: https://www.tiktok.com/@github\n",
      "18: https://github.com/yyx990803\n",
      "19: https://github.careers\n",
      "20: https://github.com/git-guides\n",
      "21: https://github.com/#start-of-content\n",
      "22: https://desktop.github.com\n",
      "23: https://github.com/dayhaysoos\n",
      "24: https://github.com/features/codespaces\n",
      "25: https://github.com/enterprise/startups\n",
      "26: https://github.com/features/copilot\n",
      "27: https://github.com/topics\n",
      "28: https://resources.github.com/devops/tools/compare\n",
      "29: https://www.youtube.com/github\n",
      "30: https://github.com/resources/articles\n",
      "31: https://github.blog/2023-01-25-100-million-developers-and-counting/\n",
      "32: https://services.github.com\n",
      "33: https://github.com/collections\n",
      "34: https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F&source=header-home\n",
      "35: https://www.twitch.tv/github\n",
      "36: https://shop.github.com\n",
      "37: https://github.com/solutions/ci-cd\n",
      "38: https://github.com/features\n",
      "39: https://github.com/features/issues\n",
      "40: https://resources.github.com/learn/pathways\n",
      "41: https://github.com/prophen\n",
      "42: https://github.com/#security\n",
      "43: https://www.linkedin.com/company/github\n",
      "44: https://www.githubstatus.com\n",
      "45: https://resources.github.com/security/sast/\n",
      "46: https://github.com/solutions/industries/healthcare\n",
      "47: https://github.com/eslint\n",
      "48: https://github.com/resources/articles/security\n",
      "49: https://github.com/resources/articles/software-development\n",
      "50: https://github.com/premium-support\n",
      "51: https://cli.github.com\n",
      "52: https://github.com/sitemap\n",
      "53: https://github.com/features/actions\n",
      "54: https://github.com/newsroom\n",
      "55: https://github.com/#collaboration\n",
      "56: https://github.com/organizations/enterprise_plan?ref_cta=Start+a+free+enterprise+trial&ref_loc=homepage+sticky+nav&ref_page=%2F\n",
      "57: https://github.com/about\n",
      "58: https://www.facebook.com/GitHub\n",
      "59: https://github.com/features/code-review\n",
      "60: https://resources.github.com/forrester/\n",
      "61: https://github.com/team\n",
      "62: https://github.com/customer-stories?type=enterprise\n",
      "63:  https://github.com/\n",
      "64: https://support.github.com?tags=dotcom-footer\n",
      "65: https://github.com/readme\n",
      "66: https://github.com/features/security/code\n",
      "67: https://github.com/login\n",
      "68: https://github.com/github\n",
      "69: https://github.com/features/security/software-supply-chain\n",
      "70: https://socialimpact.github.com\n",
      "71: https://github.community\n",
      "72: https://github.com/\n",
      "73: https://githubuniverse.com/?utm_source=github&utm_medium=banner&utm_campaign=24bannerheader10li\n",
      "74: https://github.com/customer-stories\n",
      "75: https://github.com/features/discussions\n",
      "76: https://github.com/imolorhe\n",
      "77: https://partner.github.com\n",
      "78: https://github.com/mobile\n",
      "79: https://github.com/solutions/devsecops\n",
      "80: https://github.com/resources/articles/ai\n",
      "81: https://github.com/kazupon\n",
      "82: https://github.com/github/roadmap\n",
      "83: https://x.com/github\n",
      "84: https://github.com/sindresorhus\n",
      "85: https://resources.github.com/newsletter/\n",
      "86: https://github.com/features/security\n",
      "87: https://docs.github.com/site-policy/github-terms/github-terms-of-service\n",
      "88: https://docs.github.com\n",
      "89: https://github.com/sponsors\n",
      "90: https://github.com/pricing\n",
      "91: https://github.com/join?ref_cta=Sign+up+for+GitHub&ref_loc=homepage+sticky+nav&ref_page=%2F&source=homepage-sticky-nav\n",
      "92: https://github.com/commandpost\n",
      "93: https://github.com/organizations/enterprise_plan?ref_cta=Start+a+free+enterprise+trial&ref_loc=Home+campaign+hero&ref_page=%2F\n",
      "94: https://github.com/solutions/industries/financial-services\n",
      "95: https://resources.github.com\n",
      "96: https://github.com/resources/articles/devops\n",
      "97: https://docs.github.com/site-policy/privacy-policies/github-privacy-statement\n",
      "98: https://github.com/enterprise/premium-support\n",
      "99: https://github.com/trending\n",
      "\n",
      "Crawling Summary:\n",
      "Total pages crawled using BFS: 14\n",
      "Total pages crawled using DFS: 68\n",
      "Total pages crawled using A*: 16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import heapq\n",
    "\n",
    "class WebCrawler:\n",
    "    def __init__(self, base_url, max_depth=3):\n",
    "        self.base_url = base_url\n",
    "        self.visited = set()\n",
    "        self.max_depth = max_depth\n",
    "        self.priority_queue = []\n",
    "        self.indexed_links = []  # List to store all indexed links\n",
    "        \n",
    "        # Counters for each algorithm\n",
    "        self.bfs_count = 0\n",
    "        self.dfs_count = 0\n",
    "        self.a_star_count = 0\n",
    "\n",
    "    def get_html(self, url):\n",
    "        \"\"\"Fetch HTML content using requests.\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Raise an error for bad responses\n",
    "            return response.text\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching {url}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def extract_links(self, html, base_url):\n",
    "        \"\"\"Extract links from the HTML content.\"\"\"\n",
    "        links = set()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            href = link.get('href')\n",
    "            full_url = urljoin(base_url, href)\n",
    "            links.add(full_url)\n",
    "        return links\n",
    "\n",
    "    def heuristic(self, url):\n",
    "        \"\"\"Determine which algorithm to use based on the URL heuristics.\"\"\"\n",
    "        # Example heuristics for algorithm selection\n",
    "        if len(url) > 50:\n",
    "            return \"A*\"  # Use A* for longer URLs\n",
    "        elif url.count('/') > 2:\n",
    "            return \"DFS\"  # Use DFS for deeper paths\n",
    "        else:\n",
    "            return \"BFS\"  # Use BFS for shallow paths\n",
    "\n",
    "    def crawl(self, url, depth=0):\n",
    "        \"\"\"Main crawl function that dynamically switches algorithms.\"\"\"\n",
    "        if depth > self.max_depth or url in self.visited:\n",
    "            return\n",
    "\n",
    "        print(f\"Crawling: {url} at depth {depth} (Visited: {len(self.visited)})\")\n",
    "        self.visited.add(url)\n",
    "\n",
    "        html = self.get_html(url)\n",
    "        if html:\n",
    "            links = self.extract_links(html, url)\n",
    "            self.indexed_links.extend(links)  # Store all indexed links\n",
    "\n",
    "            for link in links:\n",
    "                algo = self.heuristic(link)\n",
    "\n",
    "                if algo == \"A*\":\n",
    "                    print(f\"[Using A* Algorithm] Crawling: {link}\")\n",
    "                    self.crawl_a_star(link, depth + 1)\n",
    "                elif algo == \"DFS\":\n",
    "                    print(f\"[Using DFS Algorithm] Crawling: {link}\")\n",
    "                    self.crawl_dfs(link, depth + 1)\n",
    "                else:\n",
    "                    print(f\"[Using BFS Algorithm] Crawling: {link}\")\n",
    "                    self.crawl_bfs(link, depth + 1)\n",
    "\n",
    "    def crawl_dfs(self, url, depth):\n",
    "        \"\"\"Crawl using Depth-First Search (DFS).\"\"\"\n",
    "        if depth > self.max_depth or url in self.visited:\n",
    "            return\n",
    "        self.visited.add(url)\n",
    "        self.dfs_count += 1  # Increment DFS counter\n",
    "        self.crawl(url, depth)\n",
    "\n",
    "    def crawl_bfs(self, url, depth):\n",
    "        \"\"\"Crawl using Breadth-First Search (BFS).\"\"\"\n",
    "        if depth > self.max_depth or url in self.visited:\n",
    "            return\n",
    "        self.visited.add(url)\n",
    "        self.bfs_count += 1  # Increment BFS counter\n",
    "        self.crawl(url, depth)\n",
    "\n",
    "    def crawl_a_star(self, url, depth):\n",
    "        \"\"\"Crawl using A* Search.\"\"\"\n",
    "        if depth > self.max_depth or url in self.visited:\n",
    "            return\n",
    "        self.visited.add(url)\n",
    "        self.a_star_count += 1  # Increment A* counter\n",
    "\n",
    "        priority = len(url)  # Example heuristic: prioritize shorter URLs\n",
    "        heapq.heappush(self.priority_queue, (priority, url))\n",
    "\n",
    "        while self.priority_queue:\n",
    "            priority, current_url = heapq.heappop(self.priority_queue)\n",
    "            print(f\"[A*] Processing URL with priority {priority}: {current_url}\")\n",
    "            self.crawl(current_url, depth)\n",
    "\n",
    "    def extract_content(self, link):\n",
    "        \"\"\"Fetch content from the selected link.\"\"\"\n",
    "        content = self.get_html(link)\n",
    "        if content:\n",
    "            print(\"\\nContent extracted from the selected link:\")\n",
    "            print(content[:500])  # Print the first 500 characters\n",
    "\n",
    "    def run(self):\n",
    "        print(\"Starting crawl...\")\n",
    "        self.crawl(self.base_url)\n",
    "\n",
    "        print(\"\\nIndexed Links:\")\n",
    "        unique_links = list(set(self.indexed_links))  # Remove duplicates\n",
    "        for idx, link in enumerate(unique_links):\n",
    "            print(f\"{idx + 1}: {link}\")\n",
    "\n",
    "        print(f\"\\nCrawling Summary:\\n\"\n",
    "              f\"Total pages crawled using BFS: {self.bfs_count}\\n\"\n",
    "              f\"Total pages crawled using DFS: {self.dfs_count}\\n\"\n",
    "              f\"Total pages crawled using A*: {self.a_star_count}\\n\")\n",
    "\n",
    "        while True:\n",
    "            choice = input(\"\\nEnter the number of the link you want to extract info from (or 'exit' to quit): \")\n",
    "            if choice.lower() == 'exit':\n",
    "                break\n",
    "            try:\n",
    "                link_index = int(choice) - 1\n",
    "                if 0 <= link_index < len(unique_links):\n",
    "                    selected_link = unique_links[link_index]\n",
    "                    self.extract_content(selected_link)\n",
    "                else:\n",
    "                    print(\"Invalid choice. Please select a valid link number.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a number or 'exit'.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    base_url = input(\"Enter the starting URL: \")  # Prompt for starting URL\n",
    "    crawler = WebCrawler(base_url)\n",
    "\n",
    "    crawler.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fbb064-cbcb-4f8e-b3c2-c590d76fc72b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
